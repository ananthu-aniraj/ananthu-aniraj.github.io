<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Ananthu Aniraj </title> <meta name="author" content="Ananthu Aniraj"> <meta name="description" content="A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. "> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a26b1b0e2d9c9dd2e5ed17c987a37731"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link rel="preconnect" href="https://fonts.googleapis.com"> <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?9dbe0c76bacd463500b79ed6a86e27ac"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link href="https://fonts.googleapis.com/css2?family=Merriweather:ital,wght@0,300;0,400;0,700;0,900;1,300;1,400;1,700;1,900&amp;display=swap" rel="stylesheet"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%F0%9F%9A%80&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://ananthu-aniraj.github.io/"> <script src="/assets/js/theme.js?bd888c560287cd675855c7662a167c4a"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>initTheme();</script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item active"> <a class="nav-link" href="/">About <span class="sr-only">(current)</span> </a> </li> <li class="nav-item "> <a class="nav-link" href="/pub">Publications </a> </li> <li class="nav-item "> <a class="nav-link" href="/repositories/">Repositories </a> </li> <li class="nav-item "> <a class="nav-link" href="/assets/pdf/Ananthu_Aniraj_CV_website.pdf">CV </a> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title"> <span class="font-weight-bold">Ananthu</span> Aniraj </h1> <p class="desc">PhD Researcher | Inria</p> </header> <article> <div class="profile float-right"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/prof_pic-480.webp 480w,/assets/img/prof_pic-800.webp 800w,/assets/img/prof_pic-1400.webp 1400w," type="image/webp" sizes="(min-width: 850px) 246.0px, (min-width: 576px) 30vw, 95vw"> <img src="/assets/img/prof_pic.jpg?1c593042e11d5f24894d5515c441f950" class="img-fluid z-depth-1 rounded" width="100%" height="auto" alt="prof_pic.jpg" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div class="clearfix"> <p>I am a PhD researcher at <a href="https://www.inria.fr/en" rel="external nofollow noopener" target="_blank">Inria</a>, France, under the supervision of <a href="https://scholar.google.com/citations?user=IUqydU0AAAAJ" rel="external nofollow noopener" target="_blank">Dr. Diego Marcos</a>, in association with the <a href="https://www.umontpellier.fr/" rel="external nofollow noopener" target="_blank">University of Montpellier</a>. My research specializes in Interpretable-by-Design computer vision systems for fine-grained species classification. I am also co-supervised by <a href="https://cassiofragadantas.github.io/" rel="external nofollow noopener" target="_blank">Dr. Cassio Fraga Dantas</a> and <a href="https://scholar.google.com/citations?user=C8zfH3kAAAAJ" rel="external nofollow noopener" target="_blank">Dr. Dino Ienco</a>. More information about my research group can be found <a href="https://team.inria.fr/evergreen/" rel="external nofollow noopener" target="_blank">here</a>.</p> <p>I hold an M.Sc. in Embedded Systems from the <a href="https://www.utwente.nl/en/" rel="external nofollow noopener" target="_blank">University of Twente</a>, and a B.Tech in Electrical and Electronics Engineering with distinction from the <a href="https://www.keralauniversity.ac.in/" rel="external nofollow noopener" target="_blank">University of Kerala</a>.</p> <p>During my Master’s Degree, I worked on a project in collaboration with <a href="https://www.lely.com/en/" rel="external nofollow noopener" target="_blank">Lely</a> on the development of a computer vision system for instance-level part segmentation of cows. My thesis work was supervised by Dr. Yan Li, <a href="https://people.utwente.nl/n.strisciuglio" rel="external nofollow noopener" target="_blank">Dr. Nicola Strisciuglio</a>, and <a href="https://people.utwente.nl/l.j.spreeuwers" rel="external nofollow noopener" target="_blank">Dr. Luuk Spreeuwers</a>.</p> <p>Before pursuing my PhD, I worked as a Computer Vision and Machine Learning R&amp;D Engineer. I was mentored by Dr. Yan Li at Lely, where I contributed to innovative computer vision solutions for dairy farms. My work included developing machine learning algorithms for automated health monitoring of cows through multi-camera setups, as well as adapting semantic segmentation algorithms for visual scene understanding in customized farm environments.</p> <p>I am passionate about developing AI systems that are not only accurate but also interpretable. I believe that interpretability is key to building trust in AI systems. I am also committed to using AI to solve real-world problems and am a strong advocate for reproducible research.</p> </div> <h2> <a href="/news/" style="color: inherit">news</a> </h2> <div class="news"> <div class="table-responsive"> <table class="table table-sm table-borderless" overflow="auto"> <tr> <th scope="row" style="width: 20%">Jan 08, 2025</th> <td> My ECCV presentation on PDiscoFormer is now available on the conference website. You can watch it <a href="https://eccv.ecva.net/virtual/2024/oral/125" rel="external nofollow noopener" target="_blank">here</a>. </td> </tr> <tr> <th scope="row" style="width: 20%">Jul 18, 2024</th> <td> <a class="news-title" href="/news/announcement_2/">Pdiscoformer has been accepted at ECCV 2024 as an oral presentation!</a> </td> </tr> <tr> <th scope="row" style="width: 20%">Aug 23, 2023</th> <td> <a class="news-title" href="/news/announcement_1/">Masking Strategies has been accepted at ICCVW-OODCV 2023</a> </td> </tr> </table> </div> </div> <h2> <a href="/publications/" style="color: inherit">selected publications</a> </h2> <div class="publications"> <ol class="bibliography"> <li><div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100" style="background-color:#009f36"> <a href="https://www.computer.org/csdl/proceedings/iccvw/2023/1TangBBH5cI" rel="external nofollow noopener" target="_blank">ICCVW2023</a> </abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/LM_EM_alternate-480.webp 480w,/assets/img/publication_preview/LM_EM_alternate-800.webp 800w,/assets/img/publication_preview/LM_EM_alternate-1400.webp 1400w," type="image/webp" sizes="200px"> <img src="/assets/img/publication_preview/LM_EM_alternate.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="LM_EM_alternate.png" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div id="10351024" class="col-sm-8"> <div class="title">Masking Strategies for Background Bias Removal in Computer Vision Models</div> <div class="author"> <em>Ananthu Aniraj</em>, <a href="https://cassiofragadantas.github.io/" rel="external nofollow noopener" target="_blank">Cassio F. Dantas</a>, <a href="https://scholar.google.com/citations?user=C8zfH3kAAAAJ" rel="external nofollow noopener" target="_blank">Dino Ienco</a>, and <a href="https://scholar.google.com/citations?user=IUqydU0AAAAJ" rel="external nofollow noopener" target="_blank">Diego Marcos</a> </div> <div class="periodical"> <em>In 2023 IEEE/CVF International Conference on Computer Vision Workshops (ICCVW)</em>, Oct 2023 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="http://arxiv.org/abs/2308.12127" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://openaccess.thecvf.com/content/ICCV2023W/OODCV/html/Aniraj_Masking_Strategies_for_Background_Bias_Removal_in_Computer_Vision_Models_ICCVW_2023_paper.html" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> <a href="https://openaccess.thecvf.com/content/ICCV2023W/OODCV/papers/Aniraj_Masking_Strategies_for_Background_Bias_Removal_in_Computer_Vision_Models_ICCVW_2023_paper.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://github.com/ananthu-aniraj/masking_strategies_bias_removal" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="abstract hidden"> <p>Models for fine-grained image classification tasks, where the difference between some classes can be extremely subtle and the number of samples per class tends to be low, are particularly prone to picking up background-related biases and demand robust methods to handle potential examples with out-of-distribution (OOD) backgrounds. To gain deeper insights into this critical problem, our research investigates the impact of background-induced bias on fine-grained image classification, evaluating standard backbone models such as Convolutional Neural Network (CNN) and Vision Transformers (ViT). We explore two masking strategies to mitigate background-induced bias: Early masking, which removes background information at the (input) image level, and late masking, which selectively masks high-level spatial features corresponding to the background. Extensive experiments assess the behavior of CNN and ViT models under different masking strategies, with a focus on their generalization to OOD backgrounds. The obtained findings demonstrate that both proposed strategies enhance OOD performance compared to the baseline models, with early masking consistently exhibiting the best OOD performance. Notably, a ViT variant employing GAP-Pooled Patch token-based classification combined with early masking achieves the highest OOD robustness.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">10351024</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Aniraj, Ananthu and Dantas, Cassio F. and Ienco, Dino and Marcos, Diego}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{2023 IEEE/CVF International Conference on Computer Vision Workshops (ICCVW)}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Masking Strategies for Background Bias Removal in Computer Vision Models}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2023}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{}</span><span class="p">,</span>
  <span class="na">issn</span> <span class="p">=</span> <span class="s">{}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{4399-4407}</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{computer vision;computational modeling;transformers;data models;robustness;convolutional neural networks;task analysis}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1109/ICCVW60793.2023.00474}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://doi.ieeecomputersociety.org/10.1109/ICCVW60793.2023.00474}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{IEEE Computer Society}</span><span class="p">,</span>
  <span class="na">address</span> <span class="p">=</span> <span class="s">{Los Alamitos, CA, USA}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">oct</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div></li> <li><div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100" style="background-color:#009f36"> <a href="https://link.springer.com/book/10.1007/978-3-031-73232-4" rel="external nofollow noopener" target="_blank">ECCV2024</a> </abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/PdisconetV2-main-480.webp 480w,/assets/img/publication_preview/PdisconetV2-main-800.webp 800w,/assets/img/publication_preview/PdisconetV2-main-1400.webp 1400w," type="image/webp" sizes="200px"> <img src="/assets/img/publication_preview/PdisconetV2-main.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="PdisconetV2-main.png" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div id="aniraj2024pdiscoformer" class="col-sm-8"> <div class="title">PDiscoFormer: Relaxing Part Discovery Constraints with Vision Transformers</div> <div class="author"> <em>Ananthu Aniraj</em>, <a href="https://cassiofragadantas.github.io/" rel="external nofollow noopener" target="_blank">Cassio F. Dantas</a>, <a href="https://scholar.google.com/citations?user=C8zfH3kAAAAJ" rel="external nofollow noopener" target="_blank">Dino Ienco</a>, and <a href="https://scholar.google.com/citations?user=IUqydU0AAAAJ" rel="external nofollow noopener" target="_blank">Diego Marcos</a> </div> <div class="periodical"> <em>In ECCV 2024 - 18th European Conference on Computer Vision</em>, Sep 2024 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="http://arxiv.org/abs/2407.04538v3" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://link.springer.com/chapter/10.1007/978-3-031-73013-9_15" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> <a href="https://www.ecva.net/papers/eccv_2024/papers_ECCV/papers/11397.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://github.com/ananthu-aniraj/pdiscoformer" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="abstract hidden"> <p>Computer vision methods that explicitly detect object parts and reason on them are a step towards inherently interpretable models. Existing approaches that perform part discovery driven by a fine-grained classification task make very restrictive assumptions on the geometric properties of the discovered parts; they should be small and compact. Although this prior is useful in some cases, in this paper we show that pre-trained transformer-based vision models, such as self-supervised DINOv2 ViT, enable the relaxation of these constraints. In particular, we find that a total variation (TV) prior, which allows for multiple connected components of any size, substantially outperforms previous work. We test our approach on three fine-grained classification benchmarks: CUB, PartImageNet and Oxford Flowers, and compare our results to previously published methods as well as a re-implementation of the state-of-the-art method PDiscoNet with a transformer-based backbone. We consistently obtain substantial improvements across the board, both on part discovery metrics and the downstream classification task, showing that the strong inductive biases in self-supervised ViT models require to rethink the geometric priors that can be used for unsupervised part discovery.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">aniraj2024pdiscoformer</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{{PDiscoFormer: Relaxing Part Discovery Constraints with Vision Transformers}}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Aniraj, Ananthu and Dantas, Cassio F. and Ienco, Dino and Marcos, Diego}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{{ECCV 2024 - 18th European Conference on Computer Vision}}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">sep</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{{Springer Nature Switzerland}}</span><span class="p">,</span>
  <span class="na">series</span> <span class="p">=</span> <span class="s">{Lecture Notes in Computer Science}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{15143}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{256-272}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1007/978-3-031-73013-9\_15}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div></li> <li><div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">European-Patent</abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/calving_monitoring-480.webp 480w,/assets/img/publication_preview/calving_monitoring-800.webp 800w,/assets/img/publication_preview/calving_monitoring-1400.webp 1400w," type="image/webp" sizes="200px"> <img src="/assets/img/publication_preview/calving_monitoring.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="calving_monitoring.png" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div id="meeuwesen_system_2024" class="col-sm-8"> <div class="title">System for monitoring a calving mammal</div> <div class="author"> Adrianus Cornelis Maria MEEUWESEN, <a href="https://www.linkedin.com/in/yan-li-49a60253/" rel="external nofollow noopener" target="_blank">Yan Li</a>, and <em>Ananthu ANIRAJ</em> </div> <div class="periodical"> Oct 2024 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://patents.google.com/patent/EP4291133B1/en" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> <a href="https://patentimages.storage.googleapis.com/93/5f/aa/d3459b40395f51/EP4291133B1.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> <div class="abstract hidden"> <p>The present invention relates to a calving monitoring system for monitoring an animal at the end of the expected gestation period, comprising a camera device for repeatedly taking images of the animal, said images being composed of pixels, a control unit for the calving monitoring system, connected to the camera device, which is configured to generate calving information from the images taken, and an alert device for sending an alert message according to the calving information generated, wherein the control unit is configured so as, in each image taken, to determine a parameter value relating to first pixels of said taken images as a time-dependent parametric function, and to detect contractions when said parameter value meets a predetermined contraction criterion, wherein the control unit generates calving information which comprises an indicator of the contractions detected.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@patent</span><span class="p">{</span><span class="nl">meeuwesen_system_2024</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{System for monitoring a calving mammal}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://patents.google.com/patent/EP4291133B1/en}</span><span class="p">,</span>
  <span class="na">nationality</span> <span class="p">=</span> <span class="s">{EP}</span><span class="p">,</span>
  <span class="na">assignee</span> <span class="p">=</span> <span class="s">{Lely Patent NV}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{EP4291133B1}</span><span class="p">,</span>
  <span class="na">urldate</span> <span class="p">=</span> <span class="s">{2024-12-10}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{MEEUWESEN, Adrianus Cornelis Maria and Li, Yan and ANIRAJ, Ananthu}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">oct</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{animal, calving, contractions, control unit, torso}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div></li> </ol> </div> <div class="social"> <div class="contact-icons"> <a href="mailto:%61%6E%61%6E%74%68%75.%61%6E%69%72%61%6A@%69%6E%72%69%61.%66%72" title="email"><i class="fa-solid fa-envelope"></i></a> <a href="https://orcid.org/0009-0003-4521-036X" title="ORCID" rel="external nofollow noopener" target="_blank"><i class="ai ai-orcid"></i></a> <a href="https://scholar.google.com/citations?user=fQvQIsUAAAAJ" title="Google Scholar" rel="external nofollow noopener" target="_blank"><i class="ai ai-google-scholar"></i></a> <a href="https://github.com/ananthu-aniraj" title="GitHub" rel="external nofollow noopener" target="_blank"><i class="fa-brands fa-github"></i></a> <a href="https://www.linkedin.com/in/ananthu-aniraj-03059082" title="LinkedIn" rel="external nofollow noopener" target="_blank"><i class="fa-brands fa-linkedin"></i></a> <a href="/feed.xml" title="RSS Feed"><i class="fa-solid fa-square-rss"></i></a> </div> <div class="contact-note">Please reach out to me through LinkedIn (for professional inquiries) or email (for interest in research collaboration). </div> </div> </article> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2025 Ananthu Aniraj. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Last updated: January 09, 2025. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?3e7054dc4d3e3dd8f0731a48453e618e"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?3577194613afa04501eb52f8f4164de9" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> <script src="/assets/js/vanilla-back-to-top.min.js?982c80efc910ea9a6203400dcbd0a3af"></script> <script>addBackToTop();</script> <script type="module" src="/assets/js/search/ninja-keys.min.js?101922ace415c3a07fdb5a0877aad48f"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script>let searchTheme=determineComputedTheme();const ninjaKeys=document.querySelector("ninja-keys");"dark"===searchTheme?ninjaKeys.classList.add("dark"):ninjaKeys.classList.remove("dark");const openSearchModal=()=>{const e=$("#navbarNav");e.hasClass("show")&&e.collapse("hide"),ninjaKeys.open()};</script> <script>const ninja=document.querySelector("ninja-keys");ninja.data=[{id:"nav-about",title:"About",section:"Navigation",handler:()=>{window.location.href="/"}},{id:"nav-publications",title:"Publications",description:"publications by categories in reversed chronological order. generated by jekyll-scholar.",section:"Navigation",handler:()=>{window.location.href="/pub"}},{id:"nav-repositories",title:"Repositories",description:"A list of repositories I have contributed to.",section:"Navigation",handler:()=>{window.location.href="/repositories/"}},{id:"nav-cv",title:"CV",description:"",section:"Navigation",handler:()=>{window.location.href="/assets/pdf/Ananthu_Aniraj_CV_website.pdf"}},{id:"post-google-gemini-updates-flash-1-5-gemma-2-and-project-astra",title:'Google Gemini updates: Flash 1.5, Gemma 2 and Project Astra <svg width="1.2rem" height="1.2rem" top=".5rem" viewBox="0 0 40 40" xmlns="http://www.w3.org/2000/svg"><path d="M17 13.5v6H5v-12h6m3-3h6v6m0-6-9 9" class="icon_svg-stroke" stroke="#999" stroke-width="1.5" fill="none" fill-rule="evenodd" stroke-linecap="round" stroke-linejoin="round"></path></svg>',description:"We\u2019re sharing updates across our Gemini family of models and a glimpse of Project Astra, our vision for the future of AI assistants.",section:"Posts",handler:()=>{window.open("https://blog.google/technology/ai/google-gemini-update-flash-ai-assistant-io-2024/","_blank")}},{id:"post-a-post-with-tabs",title:"a post with tabs",description:"this is what included tabs in a post could look like",section:"Posts",handler:()=>{window.location.href="/blog/2024/tabs/"}},{id:"post-a-post-with-typograms",title:"a post with typograms",description:"this is what included typograms code could look like",section:"Posts",handler:()=>{window.location.href="/blog/2024/typograms/"}},{id:"post-a-post-that-can-be-cited",title:"a post that can be cited",description:"this is what a post that can be cited looks like",section:"Posts",handler:()=>{window.location.href="/blog/2024/post-citation/"}},{id:"post-a-post-with-pseudo-code",title:"a post with pseudo code",description:"this is what included pseudo code could look like",section:"Posts",handler:()=>{window.location.href="/blog/2024/pseudocode/"}},{id:"post-a-post-with-code-diff",title:"a post with code diff",description:"this is how you can display code diffs",section:"Posts",handler:()=>{window.location.href="/blog/2024/code-diff/"}},{id:"post-a-post-with-advanced-image-components",title:"a post with advanced image components",description:"this is what advanced image components could look like",section:"Posts",handler:()=>{window.location.href="/blog/2024/advanced-images/"}},{id:"post-a-post-with-vega-lite",title:"a post with vega lite",description:"this is what included vega lite code could look like",section:"Posts",handler:()=>{window.location.href="/blog/2024/vega-lite/"}},{id:"post-a-post-with-geojson",title:"a post with geojson",description:"this is what included geojson code could look like",section:"Posts",handler:()=>{window.location.href="/blog/2024/geojson-map/"}},{id:"post-a-post-with-echarts",title:"a post with echarts",description:"this is what included echarts code could look like",section:"Posts",handler:()=>{window.location.href="/blog/2024/echarts/"}},{id:"post-a-post-with-chart-js",title:"a post with chart.js",description:"this is what included chart.js code could look like",section:"Posts",handler:()=>{window.location.href="/blog/2024/chartjs/"}},{id:"post-a-post-with-tikzjax",title:"a post with TikZJax",description:"this is what included TikZ code could look like",section:"Posts",handler:()=>{window.location.href="/blog/2023/tikzjax/"}},{id:"post-a-post-with-bibliography",title:"a post with bibliography",description:"an example of a blog post with bibliography",section:"Posts",handler:()=>{window.location.href="/blog/2023/post-bibliography/"}},{id:"post-a-post-with-jupyter-notebook",title:"a post with jupyter notebook",description:"an example of a blog post with jupyter notebook",section:"Posts",handler:()=>{window.location.href="/blog/2023/jupyter-notebook/"}},{id:"post-a-post-with-custom-blockquotes",title:"a post with custom blockquotes",description:"an example of a blog post with custom blockquotes",section:"Posts",handler:()=>{window.location.href="/blog/2023/custom-blockquotes/"}},{id:"post-a-post-with-table-of-contents-on-a-sidebar",title:"a post with table of contents on a sidebar",description:"an example of a blog post with table of contents on a sidebar",section:"Posts",handler:()=>{window.location.href="/blog/2023/sidebar-table-of-contents/"}},{id:"post-a-post-with-audios",title:"a post with audios",description:"this is what included audios could look like",section:"Posts",handler:()=>{window.location.href="/blog/2023/audios/"}},{id:"post-a-post-with-videos",title:"a post with videos",description:"this is what included videos could look like",section:"Posts",handler:()=>{window.location.href="/blog/2023/videos/"}},{id:"post-displaying-beautiful-tables-with-bootstrap-tables",title:"displaying beautiful tables with Bootstrap Tables",description:"an example of how to use Bootstrap Tables",section:"Posts",handler:()=>{window.location.href="/blog/2023/tables/"}},{id:"post-a-post-with-table-of-contents",title:"a post with table of contents",description:"an example of a blog post with table of contents",section:"Posts",handler:()=>{window.location.href="/blog/2023/table-of-contents/"}},{id:"post-a-post-with-giscus-comments",title:"a post with giscus comments",description:"an example of a blog post with giscus comments",section:"Posts",handler:()=>{window.location.href="/blog/2022/giscus-comments/"}},{id:"post-displaying-external-posts-on-your-al-folio-blog",title:'Displaying External Posts on Your al-folio Blog <svg width="1.2rem" height="1.2rem" top=".5rem" viewBox="0 0 40 40" xmlns="http://www.w3.org/2000/svg"><path d="M17 13.5v6H5v-12h6m3-3h6v6m0-6-9 9" class="icon_svg-stroke" stroke="#999" stroke-width="1.5" fill="none" fill-rule="evenodd" stroke-linecap="round" stroke-linejoin="round"></path></svg>',description:"",section:"Posts",handler:()=>{window.open("https://medium.com/@al-folio/displaying-external-posts-on-your-al-folio-blog-b60a1d241a0a?source=rss-17feae71c3c4------2","_blank")}},{id:"post-a-post-with-redirect",title:"a post with redirect",description:"you can also redirect to assets like pdf",section:"Posts",handler:()=>{window.location.href="/assets/pdf/example_pdf.pdf"}},{id:"post-a-post-with-diagrams",title:"a post with diagrams",description:"an example of a blog post with diagrams",section:"Posts",handler:()=>{window.location.href="/blog/2021/diagrams/"}},{id:"post-a-distill-style-blog-post",title:"a distill-style blog post",description:"an example of a distill-style blog post and main elements",section:"Posts",handler:()=>{window.location.href="/blog/2021/distill/"}},{id:"post-a-post-with-twitter",title:"a post with twitter",description:"an example of a blog post with twitter",section:"Posts",handler:()=>{window.location.href="/blog/2020/twitter/"}},{id:"post-a-post-with-disqus-comments",title:"a post with disqus comments",description:"an example of a blog post with disqus comments",section:"Posts",handler:()=>{window.location.href="/blog/2015/disqus-comments/"}},{id:"post-a-post-with-math",title:"a post with math",description:"an example of a blog post with some math",section:"Posts",handler:()=>{window.location.href="/blog/2015/math/"}},{id:"post-a-post-with-code",title:"a post with code",description:"an example of a blog post with some code",section:"Posts",handler:()=>{window.location.href="/blog/2015/code/"}},{id:"post-a-post-with-images",title:"a post with images",description:"this is what included images could look like",section:"Posts",handler:()=>{window.location.href="/blog/2015/images/"}},{id:"post-a-post-with-formatting-and-links",title:"a post with formatting and links",description:"march &amp; april, looking forward to summer",section:"Posts",handler:()=>{window.location.href="/blog/2015/formatting-and-links/"}},{id:"news-masking-strategies-has-been-accepted-at-iccvw-oodcv-2023",title:"Masking Strategies has been accepted at ICCVW-OODCV 2023",description:"",section:"News",handler:()=>{window.location.href="/news/announcement_1/"}},{id:"news-pdiscoformer-has-been-accepted-at-eccv-2024-as-an-oral-presentation",title:"Pdiscoformer has been accepted at ECCV 2024 as an oral presentation!",description:"",section:"News",handler:()=>{window.location.href="/news/announcement_2/"}},{id:"news-my-eccv-presentation-on-pdiscoformer-is-now-available-on-the-conference-website-you-can-watch-it-here",title:"My ECCV presentation on PDiscoFormer is now available on the conference website. You...",description:"",section:"News"},{id:"projects-project-1",title:"project 1",description:"with background image",section:"Projects",handler:()=>{window.location.href="/projects/1_project/"}},{id:"projects-project-2",title:"project 2",description:"a project with a background image and giscus comments",section:"Projects",handler:()=>{window.location.href="/projects/2_project/"}},{id:"projects-project-3-with-very-long-name",title:"project 3 with very long name",description:"a project that redirects to another website",section:"Projects",handler:()=>{window.location.href="/projects/3_project/"}},{id:"projects-project-4",title:"project 4",description:"another without an image",section:"Projects",handler:()=>{window.location.href="/projects/4_project/"}},{id:"projects-project-5",title:"project 5",description:"a project with a background image",section:"Projects",handler:()=>{window.location.href="/projects/5_project/"}},{id:"projects-project-6",title:"project 6",description:"a project with no image",section:"Projects",handler:()=>{window.location.href="/projects/6_project/"}},{id:"projects-project-7",title:"project 7",description:"with background image",section:"Projects",handler:()=>{window.location.href="/projects/7_project/"}},{id:"projects-project-8",title:"project 8",description:"an other project with a background image and giscus comments",section:"Projects",handler:()=>{window.location.href="/projects/8_project/"}},{id:"projects-project-9",title:"project 9",description:"another project with an image \ud83c\udf89",section:"Projects",handler:()=>{window.location.href="/projects/9_project/"}},{id:"socials-email",title:"Send email",section:"Socials",handler:()=>{window.open("mailto:%61%6E%61%6E%74%68%75.%61%6E%69%72%61%6A@%69%6E%72%69%61.%66%72","_blank")}},{id:"socials-orcid",title:"ORCID",section:"Socials",handler:()=>{window.open("https://orcid.org/0009-0003-4521-036X","_blank")}},{id:"socials-google-scholar",title:"Google Scholar",section:"Socials",handler:()=>{window.open("https://scholar.google.com/citations?user=fQvQIsUAAAAJ","_blank")}},{id:"socials-github",title:"GitHub",section:"Socials",handler:()=>{window.open("https://github.com/ananthu-aniraj","_blank")}},{id:"socials-linkedin",title:"LinkedIn",section:"Socials",handler:()=>{window.open("https://www.linkedin.com/in/ananthu-aniraj-03059082","_blank")}},{id:"socials-rss",title:"RSS Feed",section:"Socials",handler:()=>{window.open("/feed.xml","_blank")}},{id:"light-theme",title:"Change theme to light",description:"Change the theme of the site to Light",section:"Theme",handler:()=>{setThemeSetting("light")}},{id:"dark-theme",title:"Change theme to dark",description:"Change the theme of the site to Dark",section:"Theme",handler:()=>{setThemeSetting("dark")}},{id:"system-theme",title:"Use system default theme",description:"Change the theme of the site to System Default",section:"Theme",handler:()=>{setThemeSetting("system")}}];</script> <script src="/assets/js/shortcut-key.js?6f508d74becd347268a7f822bca7309d"></script> </body> </html>